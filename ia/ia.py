import re
import json
from typing import Dict, List, Optional, Tuple
import numpy as np
import pandas as pd
import streamlit as st
import requests

try:
    from langchain_openai import ChatOpenAI
    from langchain.schema import SystemMessage, HumanMessage
except Exception:
    ChatOpenAI = None
    SystemMessage = HumanMessage = None


# --------- CONFIG ------------
APP_NAME = "Hola soy MARIA, ¬øEn que puedo ayudarte hoy?"
st.set_page_config(layout="wide", page_title=APP_NAME, page_icon="üçÉ")

st.markdown(
    """
    <style>
        .main { background-color:#f0f5ff; padding:0; }
        .container-box { background-color: white; border-radius: 20px; padding: 2rem; box-shadow: 0 4px 20px rgba(0,0,0,0.15); margin: 1rem auto; max-width: 1200px; }
        .chat-bubble-user { background:#F3F4F6; border-radius: 14px; padding: 12px 14px; margin: 8px 0; }
        .chat-bubble-ai { background:#EFF6FF; border:1px solid #BFDBFE; border-radius: 14px; padding: 12px 14px; margin: 8px 0; white-space: pre-wrap; }
        .footer { position: fixed; left: 0; bottom: 0; width: 100%; background-color: #111827; color: white; text-align: center; padding: 8px 0; }
        .small-note { color:#6B7280; font-size:12px; }
    </style>
    """,
    unsafe_allow_html=True,
)

OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.warning("Configura OPENAI_API_KEY en st.secrets para habilitar el motor experto (opcional).")

llm = None
if OPENAI_API_KEY and ChatOpenAI is not None:
    llm = ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=OPENAI_API_KEY)

# ---------- UTILS ------------

def slug(s: str) -> str:
    s = s.lower()
    s = re.sub(r"[√°√†√§√¢]", "a", s)
    s = re.sub(r"[√©√®√´√™]", "e", s)
    s = re.sub(r"[√≠√¨√Ø√Æ]", "i", s)
    s = re.sub(r"[√≥√≤√∂√¥]", "o", s)
    s = re.sub(r"[√∫√π√º√ª]", "u", s)
    s = re.sub(r"[^a-z0-9]+", " ", s)
    return s.strip()


# ----- CARGA DESDE URL --------

GSHEET_D_EDIT = re.compile(r"https?://docs\.google\.com/spreadsheets/d/([A-Za-z0-9-_]+)")
GSHEET_D_E = re.compile(r"https?://docs\.google\.com/spreadsheets/d/e/([A-Za-z0-9-_]+)")

def normalize_gsheet_export_url(url: str, fmt: str = "csv") -> str:
    """Normaliza enlaces de Google Sheets/Forms a export estable (csv/xlsx)."""
    u = (url or "").strip()
    if not u:
        return u

    # Ya es CSV/XLSX export
    if u.endswith(".csv") or "output=csv" in u.lower() or "format=xlsx" in u.lower():
        return re.sub(r"output=[^&#?]+", f"output={fmt}", u)

    # Publicado (d/e/.../pub)
    m_e = GSHEET_D_E.search(u)
    if m_e:
        sep = "&" if "?" in u else "?"
        return re.sub(r"output=[^&#?]+", f"output={fmt}", u) if "output=" in u else f"{u}{sep}output={fmt}"

    # Enlace de edici√≥n (d/<id>)
    m_d = GSHEET_D_EDIT.search(u)
    if m_d:
        sid = m_d.group(1)
        gid_match = re.search(r"gid=([0-9]+)", u)
        gid = f"&gid={gid_match.group(1)}" if gid_match else ""
        return f"https://docs.google.com/spreadsheets/d/{sid}/export?format={fmt}{gid}"

    return u

@st.cache_data(ttl=3600, show_spinner=True)
def load_table(url: str) -> pd.DataFrame:
    """Lee CSV/XLSX desde URL (idealmente Google Sheets publicado)."""
    if not url:
        raise ValueError("Proporciona una URL p√∫blica v√°lida (Google Sheets/Forms publicado).")
    url_norm = normalize_gsheet_export_url(url, fmt="csv")
    # CSV por defecto (admite comas decimales)
    df = pd.read_csv(url_norm)
    df.columns = df.columns.astype(str).str.replace(r"\s+", " ", regex=True).str.strip()
    return df

# Encuesta a planta activa (intenci√≥n y drivers)
ACTIVE_REQUIRED = {
    "id": ["Marca temporal", "id", "documento", "employee id", "c√©dula", "cedula"],
    "area": ["¬øEn qu√© √°rea trabajas?", "area", "√°rea", "departamento"],
    "rol": ["¬øEn qu√© cargo trabajas?", "rol", "cargo", "puesto", "title"],
    "intencion_salida": ["Estoy pensando en dejar la empresa en los pr√≥ximos 12 meses."],
}

ACTIVE_OPTIONAL = {
    # Se√±ales adicionales de intenci√≥n
    "intencion_salida_aux": ["En los √∫ltimos 3 meses, ¬øhas considerado o explorado oportunidades laborales fuera de la empresa?"],
    "preferencia_quedar": ["Si otra empresa me ofreciera un trabajo similar, preferir√≠a quedarme aqu√≠."],

    # Engagement/NPS
    "satisfaccion_general": ["En una escala de 0 a 10, ¬øQu√© probabilidad hay de que recomiendes a un amigo trabajar en esta empresa?" ],

    # Drivers (acuerdos tipo Likert)
    "autonomia": ["Siento que tengo la autonom√≠a necesaria para tomar decisiones en mi trabajo."],
    "respeto_inclusion": ["Me siento respetado(a) e incluido(a) en esta organizaci√≥n."],
    "confianza_liderazgo": ["Conf√≠o en la capacidad de liderazgo de quienes dirigen la organizaci√≥n."],
    "voz_opiniones": ["Mi voz y mis opiniones son escuchadas por la organizaci√≥n."],
    "comunicacion": ["La comunicaci√≥n dentro de la organizaci√≥n es clara, transparente y efectiva."],
    "carga_laboral": ["Mi carga de trabajo es razonable y puedo manejarla sin exceso de estr√©s."],
    "desconexion": ["Tengo la posibilidad de desconectarme y descansar fuera del horario laboral."],
    "claridad_funciones": ["S√© claramente cu√°les son mis funciones y lo que se espera de m√≠."],
    "herramientas": ["Cuento con las herramientas y recursos necesarios para hacer bien mi trabajo."],
    "crecimiento": ["Tengo oportunidades reales de crecer y desarrollarme dentro de la empresa."],
    "feedback": ["En los √∫ltimos 3 meses he recibido retroalimentaci√≥n que me ha ayudado a mejorar."],
    "jefe_respeto": ["Mi jefe me apoya y me respeta"],
    "jefe_confia": ["Mi jefe conf√≠a en mi y valora mi trabajo"],
    "reconocimiento": ["En esta empresa se valora y reconoce cuando hago bien mi trabajo."],
    "compensacion": ["Considero que mi salario es justo frente al mercado laboral colombiano."],
    "beneficios_adecuados": ["Los beneficios que ofrece la empresa son adecuados."],
    "seguridad_psico": ["Siento que puedo dar mis ideas y opiniones sin temor a represalias."],
    "respeto_equipo": ["En mi equipo hay respeto e inclusi√≥n para todos."],
    "confianza_direccion": ["Conf√≠o en la direcci√≥n que esta tomando la empresa"],
    "motivacion": ["Me siento motivado/a para dar lo mejor de mi cada d√≠a"],

    # Texto libre
    "razon_calificacion": ["¬øCu√°l fue la raz√≥n principal de tu calificaci√≥n anterior?"],
    "razones_posible_salida": ["Si alg√∫n d√≠a decidieras dejar la empresa, ¬øCu√°les ser√≠an las principales razones? (M√°ximo 3)"],
    "cambio_para_quedarte": ["Si pudieras cambiar una sola cosa en la empresa para quedarte por m√°s tiempo, ¬øQu√© ser√≠a?"],
    "comentario_adicional": ["¬øQuieres dejar alg√∫n comentario adicional que nos ayude a mejorar?"],
}

# Encuesta de egreso (leavers)
LEAVER_REQUIRED = {
    "motivo_salida": ["¬øCu√°l es el motivo principal por el que decidiste irte de la empresa?", "motivo"],
}
LEAVER_OPTIONAL = {
    "area": ["¬øEn qu√© √°rea trabajabas?", "area", "departamento"],
    "rol": ["¬øEn qu√© cargo trabajabas?", "rol", "cargo"],
    "antiguedad_meses": ["¬øCu√°nto tiempo estuviste en la empresa?", "antiguedad", "meses"],
    "nps": ["En una escala de 0 a 10, ¬øQu√© probabilidad hay de que recomiendes a un amigo trabajar en esta empresa?"],
    "otros_factores": ["Adem√°s del motivo principal, ¬øQu√© otros factores influyeron en tu decisi√≥n? (M√°ximo 3)"],
    "mejoras_retencion": ["¬øQu√© tres mejoras habr√≠an hecho m√°s probable que te quedaras en la empresa?"],
    "sugerencia_final": ["¬øQuieres dejarnos alguna sugerencia final para mejorar?"],
}

# Encuesta de Gesti√≥n Humana
HR_REQUIRED = {
    "marca": ["Marca temporal"],
}
HR_OPTIONAL = {
    # KPIs
    "headcount": ["¬øCu√°ntas personas trabajan en la organizaci√≥n actualmente?"],
    "rotacion_6m": ["¬øCual es el indice de rotaci√≥n de tu roganizaci√≥n en los ultimos 6 meses?"],
    "hr_headcount": ["¬øCu√°ntas personas trabajan en el √°rea de Gesti√≥n Humana?"],
    "vacantes_mes": ["En promedio, ¬øCu√°ntas vacantes tienen abiertas cada mes?"],
    "perfiles_dificiles": ["¬øCu√°les son los perfiles o cargos m√°s dif√≠ciles de cubrir?"],

    # Desajuste selecci√≥n
    "dificultad_ajuste": ["En los procesos de selecci√≥n hemos identificado dificultades para lograr que el perfil de los candidatos se ajuste a la complejidad real del cargo."],
    "sobrecalificados": ["En ocasiones contratamos personas sobre calificadas para cargos operativos (ej. con m√°s estudios o experiencia de la necesaria)."],
    "subcalificados": ["En ocasiones contratamos personas sub calificadas para cargos que requieren mayor experiencia o competencias."],
    "ajuste_contribuye_rotacion": ["Considero que este desajuste entre perfil y cargo contribuye a la rotaci√≥n de personal en la empresa."],
    "factores_desajuste": ["¬øQu√© factores crees que explican este desajuste?"],

    # Pr√°cticas y pol√≠ticas
    "indicadores_rotacion": ["En el √°rea llevamos indicadores claros de rotaci√≥n y los revisamos con frecuencia."],
    "medimos_tiempo_cobertura": ["Medimos el tiempo promedio para cubrir vacantes."],
    "medimos_costo_reemplazo": ["Medimos el costo de reemplazar personal."],
    "plan_retencion": ["Tenemos un plan formal de fidelizaci√≥n para los cargos m√°s cr√≠ticos."],
    "movilidad_interna": ["Contamos con pol√≠ticas de movilidad interna para ofrecer nuevas oportunidades."],
    "revision_salarial_anual": ["Revisamos los salarios al menos una vez al a√±o compar√°ndolos con el mercado."],
    "flexibilidad_laboral": ["Ofrecemos flexibilidad laboral (teletrabajo, horarios flexibles) seg√∫n el rol."],
    "encuestas_clima": ["Aplicamos encuestas de clima laboral y damos seguimiento a los resultados."],

    # Causas seg√∫n HR
    "causa_compensacion": ["Considero que la compensaci√≥n es una de las principales causas de salida de la gente."],
    "causa_jefes": ["Considero que la relaci√≥n con los jefes es una de las principales causas de salida."],
    "causa_sobrecarga": ["Considero que la sobrecarga laboral es una de las principales causas de salida."],
    "causa_proyeccion": ["Considero que la falta de proyecci√≥n es una de las principales causas de salida."],
    "causa_modalidad": ["Considero que la modalidad de trabajo (remoto/presencial) es una de las principales causas de salida."],

    # Efectividad de acciones
    "eff_ajuste_salarios": ["Nuestras acciones actuales son efectivas para ajustar salarios cuando es necesario."],
    "eff_liderazgo": ["Nuestras acciones actuales son efectivas para desarrollar programas de liderazgo."],
    "eff_bienestar": ["Nuestras acciones actuales son efectivas para promover bienestar y salud mental."],
    "eff_reconocimiento": ["Nuestras acciones actuales son efectivas para reconocer el buen desempe√±o."],
    "eff_capacitacion": ["Nuestras acciones actuales son efectivas para dar oportunidades de capacitaci√≥n y planes de carrera."],

    # Anal√≠tica y sponsorship
    "usa_analitica": ["En la empresa usamos anal√≠tica de datos para predecir riesgos de salida."],
    "sponsorship_alta_direccion": ["La alta direcci√≥n participa activamente en las acciones de fidelizaci√≥n."],

    # Segmentaci√≥n rotaci√≥n
    "identifico_quien_se_va": ["En los √∫ltimos 12 meses, ¬øla empresa ha identificado qu√© tipo de personas est√°n dejando la organizaci√≥n?"],
    "percepcion_rotacion": ["Consideras que en la mayor√≠a de los casos la rotaci√≥n actual de la empresa es"],

    # Acciones inmediatas
    "acciones_6m": ["Si tuvieras que priorizar tres acciones inmediatas para reducir la rotaci√≥n en los pr√≥ximos 6 meses, ¬øCu√°les ser√≠an?"],
}

# ----- MAPEADOR DE COLUMNAS ---

def guess_col(df: pd.DataFrame, hints: List[str], default: Optional[str] = None) -> Optional[str]:
    slugs = {slug(c): c for c in df.columns}
    for h in hints:
        if slug(h) in slugs:
            return slugs[slug(h)]
    return default

def map_cols(df: pd.DataFrame, req: Dict[str, List[str]], opt: Dict[str, List[str]]) -> Dict[str, Optional[str]]:
    m: Dict[str, Optional[str]] = {}
    for k, hints in req.items():
        c = guess_col(df, hints)
        if not c:
            c = df.columns[0]
        m[k] = c
    for k, hints in opt.items():
        m[k] = guess_col(df, hints, default=None)
    return m

# ---- PREP & SCORING LOGIC ----

KEYWORDS_BUCKETS = {
    "compensacion": ["salario", "pago", "compens", "sueldo", "bono"],
    "beneficios": ["beneficio", "prestacion", "eps", "auxilio", "bonificaci√≥n"],
    "liderazgo": ["jefe", "lider", "manager", "trato", "feedback", "retroaliment", "reconocimiento"],
    "carrera": ["crecimiento", "desarrollo", "ascenso", "aprendizaje", "formacion", "proyeccion", "carrera"],
    "carga": ["carga", "horas", "turno", "estres", "estr√©s", "burnout", "sobre carga", "sobrecarga"],
    "flexibilidad": ["flexibilidad", "teletrabajo", "hibrido", "h√≠brido", "home office", "horario", "presencial", "remoto"],
    "ambiente": ["clima", "ambiente", "equipo", "cultura", "respeto", "inclusion", "inclusi√≥n", "seguridad"],
    "comunicacion": ["comunicacion", "comunicaci√≥n", "transparencia", "informacion"],
    "herramientas": ["herramienta", "equipo", "recurso", "software"],
    "claridad_rol": ["claridad", "funciones", "objetivo", "rol"],
    "autonomia": ["autonomia", "autonom√≠a", "decisiones"],
    "seleccion_ajuste": ["ajuste", "perfil", "seleccion", "selecci√≥n", "sobrecali", "subcali"],
}

def map_spanish_likert_to_numeric(series: pd.Series) -> pd.Series:
    """Mapea respuestas en espa√±ol a n√∫meros y **garantiza dtype num√©rico**.
    - Soporta Likert textual (1..5), s√≠/no y n√∫meros ("8", "10", "10,0").
    - Convierte valores como "‚Äî", "n/a", "no aplica" en NaN.
    """
    s = series.astype(str).str.strip().str.lower()
    s = s.replace({
        "": np.nan,
        "-": np.nan,
        "‚Äî": np.nan,
        "na": np.nan,
        "n/a": np.nan,
        "no aplica": np.nan,
        "prefiero no responder": np.nan,
        "sin respuesta": np.nan,
    })

    LIKERT_ES_MAP = {
        "totalmente en desacuerdo": 1,
        "en desacuerdo": 2,
        "ni de acuerdo ni en desacuerdo": 3,
        "de acuerdo": 4,
        "totalmente de acuerdo": 5,
    }

    mapped = s.map(LIKERT_ES_MAP)

    mapped = mapped.fillna(s.replace({"s√≠": 5, "si": 5, "yes": 5, "no": 1}))

    numeric = pd.to_numeric(s.str.replace(",", ".", regex=False), errors="coerce")

    out = mapped.fillna(numeric)
    out = pd.to_numeric(out, errors="coerce")
    return out

def normalize_likert(series: pd.Series) -> pd.Series:
    """Normaliza a 0-100 soportando 1-5, 0-10 y 0-100.
    Evita errores de comparaci√≥n cuando hay strings mezclados.
    """
    s = map_spanish_likert_to_numeric(series)
    mx = s.max(skipna=True)
    if pd.notna(mx) and mx <= 5:
        return (s - 1) / 4 * 100
    if pd.notna(mx) and mx <= 10:
        return (s / 10) * 100
    return s.clip(0, 100)

def _score_agreement(series: pd.Series, positive_is_risk: bool = True) -> pd.Series:
    s = map_spanish_likert_to_numeric(series)
    mx = s.max(skipna=True)
    if pd.isna(mx):
        score = s 
    elif mx <= 5:
        score = (s - 1) / 4
    elif mx <= 10:
        score = s / 10
    else:
        score = (s.clip(0, 100)) / 100
    return score if positive_is_risk else (1 - score)

def _score_yesno(series: pd.Series, yes_risk: bool = True) -> pd.Series:
    s = series.astype(str).str.strip().str.lower()
    s = s.replace({
        "": np.nan,
        "-": np.nan,
        "‚Äî": np.nan,
        "na": np.nan,
        "n/a": np.nan,
        "no aplica": np.nan,
        "prefiero no responder": np.nan,
        "sin respuesta": np.nan,
    })
    yes = s.isin(["s√≠", "si", "yes", "true", "verdadero"]) | s.str.contains(r"\b(s[i√≠])\b", na=False)
    no = s.isin(["no", "false", "falso"]) | s.str.contains(r"\bno\b", na=False)
    base = pd.Series(np.nan, index=s.index, dtype="float")
    base[yes] = 1.0
    base[no] = 0.0

    s_num = pd.to_numeric(s.str.replace(',', '.', regex=False), errors='coerce')
    base = base.fillna(s_num.apply(lambda x: np.nan if pd.isna(x) else (1.0 if x >= 1 else 0.0)))
    return base if yes_risk else 1 - base

def infer_intent_from_active(df_active: pd.DataFrame, m_active: Dict[str, Optional[str]]) -> pd.Series:
    """Construye un score de intenci√≥n de salida combinando 2-3 se√±ales."""
    parts = []

    col_main = m_active.get("intencion_salida")
    if col_main and col_main in df_active.columns:
        parts.append(_score_agreement(df_active[col_main], positive_is_risk=True))

    col_aux = m_active.get("intencion_salida_aux")
    if col_aux and col_aux in df_active.columns:
        parts.append(_score_yesno(df_active[col_aux], yes_risk=True))

    col_stay = m_active.get("preferencia_quedar")
    if col_stay and col_stay in df_active.columns:
        parts.append(_score_agreement(df_active[col_stay], positive_is_risk=False))

    if not parts:
        return pd.Series(0.0, index=df_active.index)

    X = pd.concat(parts, axis=1)
    return X.mean(axis=1).fillna(0.0)

def correlate_with_intent(df_active: pd.DataFrame, m_active: Dict[str, Optional[str]]) -> pd.DataFrame:
    """Calcula correlaciones de drivers con intenci√≥n de salida."""
    y = infer_intent_from_active(df_active, m_active)
    drivers = {}
    skip_keys = {"id", "area", "rol", "intencion_salida", "intencion_salida_aux", "preferencia_quedar", "razones_texto"}
    for key, col in m_active.items():
        if key in skip_keys:
            continue
        if not col or col not in df_active.columns:
            continue
        x = normalize_likert(df_active[col])
        drivers[key] = x
    if not drivers:
        return pd.DataFrame()
    X = pd.DataFrame(drivers)
    corr = X.assign(intent=y).corr(numeric_only=True)["intent"].drop("intent")
    out = (
        corr.rename("correlacion_intencion")
        .sort_values(ascending=True)  # negativo = protector; positivo = riesgo
        .to_frame()
    )
    out.index.name = "driver"
    return out

def tokenize(s: str) -> List[str]:
    return re.findall(r"[a-z√°√©√≠√≥√∫√º√±0-9]+", str(s).lower())

def bucketize_reason(text: str) -> Dict[str, int]:
    tokens = tokenize(text)
    counts = {k: 0 for k in KEYWORDS_BUCKETS}
    for k, words in KEYWORDS_BUCKETS.items():
        counts[k] = sum(1 for t in tokens for w in words if w in t)
    return counts

def summarize_reasons(df_active: pd.DataFrame, df_leaver: pd.DataFrame, m_active: Dict[str, Optional[str]], m_leaver: Dict[str, Optional[str]]) -> pd.DataFrame:
    buckets = {k: 0 for k in KEYWORDS_BUCKETS}
    # Activos ‚Äì texto consolidado
    col_txt_a = m_active.get("razones_texto")
    if col_txt_a and col_txt_a in df_active.columns:
        for txt in df_active[col_txt_a].dropna().astype(str).tolist():
            counts = bucketize_reason(txt)
            for k, v in counts.items():
                buckets[k] += v
    # Egresos ‚Äì texto consolidado y motivo estructurado
    col_txt_l = m_leaver.get("comentarios")
    if col_txt_l and col_txt_l in df_leaver.columns:
        for txt in df_leaver[col_txt_l].dropna().astype(str).tolist():
            counts = bucketize_reason(txt)
            for k, v in counts.items():
                buckets[k] += v
    col_mot = m_leaver.get("motivo_salida")
    if col_mot and col_mot in df_leaver.columns:
        for txt in df_leaver[col_mot].dropna().astype(str).tolist():
            counts = bucketize_reason(txt)
            for k, v in counts.items():
                buckets[k] += v
    df = pd.DataFrame([
        {"categoria": k, "menciones": v} for k, v in buckets.items()
    ]).sort_values("menciones", ascending=False)
    df["peso_relativo_%"] = (df["menciones"] / max(1, df["menciones"].sum())) * 100
    return df

def area_risk(df_active: pd.DataFrame, m_active: Dict[str, Optional[str]]) -> pd.DataFrame:
    a_col = m_active.get("area")
    if not a_col or a_col not in df_active.columns:
        return pd.DataFrame()
    intent = infer_intent_from_active(df_active, m_active)
    # drivers principales si existen
    drv_cols_keys = [
        "satisfaccion_general", "compensacion", "jefe_respeto", "jefe_confia", "crecimiento",
        "carga_laboral", "comunicacion", "reconocimiento"
    ]
    drv_cols = [m_active.get(k) for k in drv_cols_keys]
    drv_cols = [c for c in drv_cols if c and c in df_active.columns]
    df = df_active[[a_col]].copy()
    df["intent"] = intent
    for c in drv_cols:
        df[c+"_norm"] = normalize_likert(df_active[c])
    agg = df.groupby(a_col).agg(
        intent_media=("intent", "mean"),
        n=("intent", "size"),
        **{c+"_avg": (c+"_norm", "mean") for c in drv_cols}
    ).reset_index()
    sat_key = m_active.get("satisfaccion_general")
    if sat_key and (sat_key+"_avg") in agg.columns:
        agg["riesgo"] = 0.5*agg["intent_media"] + 0.5*(100 - agg[sat_key+"_avg"]) / 100
    else:
        agg["riesgo"] = agg["intent_media"]
    agg["riesgo_%"] = (agg["riesgo"]*100).round(1)
    agg = agg.sort_values(["riesgo", "n"], ascending=[False, False])
    return agg

# --------- HR DASHBOARD -------

def to_bool(s: pd.Series) -> pd.Series:
    x = s.astype(str).str.strip().str.lower()
    yes_like = x.isin(["s√≠", "si", "yes", "true"]) | x.str.contains(r"de acuerdo|aplica|cumple|si\b|s√≠\b", na=False)
    no_like = x.isin(["no", "false"]) | x.str.contains(r"no aplica|no cumple|en desacuerdo", na=False)
    out = pd.Series(np.nan, index=x.index, dtype="float")
    out[yes_like] = 1.0
    out[no_like] = 0.0
    # fallback num√©rico
    out = out.fillna(pd.to_numeric(x.str.replace(",", ".", regex=False), errors="coerce").apply(
        lambda v: np.nan if pd.isna(v) else (1.0 if v >= 1 else 0.0)
    ))
    return out

def hr_dashboard(df_hr: pd.DataFrame, m_hr: Dict[str, Optional[str]]) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, str]:
    # KPIs simples
    kpis = []
    def _num(col_key):
        col = m_hr.get(col_key)
        if col and col in df_hr.columns:
            return pd.to_numeric(df_hr[col].astype(str).str.replace(",", ".", regex=False), errors="coerce").dropna().mean()
        return np.nan

    hc = _num("headcount")
    rot = _num("rotacion_6m")
    hr_hc = _num("hr_headcount")
    vac = _num("vacantes_mes")
    ratio_hr = (hr_hc / hc * 100) if (pd.notna(hr_hc) and pd.notna(hc) and hc > 0) else np.nan

    kpis.append({"indicador": "Headcount", "valor": hc})
    kpis.append({"indicador": "Rotaci√≥n 6m (%)", "valor": rot})
    kpis.append({"indicador": "Headcount HR", "valor": hr_hc})
    kpis.append({"indicador": "Vacantes/mes", "valor": vac})
    kpis.append({"indicador": "% HR sobre total", "valor": ratio_hr})
    kpis_df = pd.DataFrame(kpis)

    # Causas seg√∫n HR
    causas_keys = [
        ("causa_compensacion", "Compensaci√≥n"),
        ("causa_jefes", "Jefes/Liderazgo"),
        ("causa_sobrecarga", "Sobrecarga"),
        ("causa_proyeccion", "Falta de proyecci√≥n"),
        ("causa_modalidad", "Modalidad trabajo"),
    ]
    causas_rows = []
    for key, label in causas_keys:
        col = m_hr.get(key)
        if col and col in df_hr.columns:
            val = to_bool(df_hr[col]).mean()
            causas_rows.append({"causa": label, "% acuerdo": round(val*100, 1) if pd.notna(val) else np.nan})
    causas_df = pd.DataFrame(causas_rows).sort_values("% acuerdo", ascending=False) if causas_rows else pd.DataFrame()

    pract_keys = [
        ("indicadores_rotacion", "Indicadores de rotaci√≥n"),
        ("medimos_tiempo_cobertura", "Medimos tiempo de cobertura"),
        ("medimos_costo_reemplazo", "Medimos costo de reemplazo"),
        ("plan_retencion", "Plan de retenci√≥n"),
        ("movilidad_interna", "Movilidad interna"),
        ("revision_salarial_anual", "Revisi√≥n salarial anual"),
        ("flexibilidad_laboral", "Flexibilidad laboral"),
        ("encuestas_clima", "Encuestas de clima"),
        ("usa_analitica", "Anal√≠tica de rotaci√≥n"),
        ("sponsorship_alta_direccion", "Sponsorship Alta Direcci√≥n"),
        ("eff_ajuste_salarios", "Efectivo: ajuste salarios"),
        ("eff_liderazgo", "Efectivo: liderazgo"),
        ("eff_bienestar", "Efectivo: bienestar/SM"),
        ("eff_reconocimiento", "Efectivo: reconocimiento"),
        ("eff_capacitacion", "Efectivo: capacitaci√≥n/carrera"),
    ]
    pract_rows = []
    for key, label in pract_keys:
        col = m_hr.get(key)
        if col and col in df_hr.columns:
            val = to_bool(df_hr[col]).mean()
            pract_rows.append({"pr√°ctica": label, "% s√≠/efectivo": round(val*100, 1) if pd.notna(val) else np.nan})
    pract_df = pd.DataFrame(pract_rows).sort_values("% s√≠/efectivo", ascending=False) if pract_rows else pd.DataFrame()

    # Campos de texto
    perfiles = m_hr.get("perfiles_dificiles")
    acciones = m_hr.get("acciones_6m")
    text_concat = []
    if perfiles and perfiles in df_hr.columns:
        text_concat += ["Perfiles dif√≠ciles: " + "; ".join(df_hr[perfiles].dropna().astype(str).tolist())]
    if acciones and acciones in df_hr.columns:
        text_concat += ["Acciones 6m sugeridas: " + "; ".join(df_hr[acciones].dropna().astype(str).tolist())]
    text_blob = " | ".join(text_concat)

    return kpis_df, causas_df, pract_df, text_blob

# --------- PROMPTS -----------
SYSTEM_PROMPT = (
    "Eres MARIA, una consultora ejecutiva experta en retenci√≥n y fidelizaci√≥n de talento y reducci√≥n de rotaci√≥n. "
    "Siempre respondes en espa√±ol, en tono claro, ejecutivo y accionable. "
    "Eres rigurosa con supuestos; separas 'dato' de 'supuesto' y justificas. "
    "Entregas diagn√≥stico de drivers de salida, priorizaci√≥n de iniciativas (alto impacto/baja complejidad), "
    "y hoja de ruta trimestral con responsables y m√©tricas. "
    "Evitas lenguaje discriminatorio; promueves decisiones basadas en evidencia. "
    "Cuando se provea contexto de HR, alinea recomendaciones con beneficios y restricciones actuales. "
    "Incluye advertencia breve: 'Contenido referencial; no reemplaza asesor√≠a legal/SSO.'"
)

CHAT_INSTRUCTIONS = """
Responde como experta en **retenci√≥n**, **fidelizaci√≥n** y **experiencia del colaborador**.
- Identifica drivers de riesgo y protectores a partir de correlaciones y texto libre.
- Prioriza acciones en 3 horizontes: quick wins (0-30 d√≠as), 60-90 d√≠as, 90-180 d√≠as.
- Usa palancas: compensaci√≥n, liderazgo, carrera, flexibilidad, carga, beneficios.
- Sugiere m√©tricas: intenci√≥n de salida, tiempo de cobertura de vacantes, eNPS, % adopci√≥n de beneficios clave.
- No inventes datos: si faltan, expl√≠citalo y sugiere c√≥mo obtenerlos.
- Cierra con: *Contenido referencial; no reemplaza asesor√≠a legal/SSO.*
"""

def build_llm_answer(base_context: Dict[str, object], user_q: str) -> str:
    if llm is None or SystemMessage is None or HumanMessage is None:
        return (
            "Motor experto deshabilitado. Agrega `OPENAI_API_KEY` en `st.secrets` para activar respuestas generativas.\n\n"
            "Puedes seguir usando el Tab de Conclusiones para el diagn√≥stico determinista."
        )
    system = SystemMessage(content=SYSTEM_PROMPT)
    human = HumanMessage(content=f"Contexto JSON (si disponible): {json.dumps(base_context, ensure_ascii=False)}\n\nPregunta: {user_q}\n\nInstrucciones espec√≠ficas:\n{CHAT_INSTRUCTIONS}")
    try:
        resp = llm.invoke([system, human])
        return resp.content
    except Exception as e:
        return f"Error al consultar el modelo: {e}\n\nSugerencia: verifica OPENAI_API_KEY en st.secrets."

# -------------- UI -----------
st.markdown("<div class='container-box'>", unsafe_allow_html=True)
st.title(f"üçÉ {APP_NAME}")

with st.sidebar:
    st.header("‚öôÔ∏è Origen de datos (URLs)")
    st.caption("Los enlaces se cargan autom√°ticamente desde tu cuenta.")

    # ‚ö†Ô∏è El email llega desde React en la URL del iframe
    email_usuario = st.query_params.get("email", None)  # ej: http://localhost:8501/?email=user@gmail.com

    url_active = url_leaver = url_hr = None

    if email_usuario:
        try:
            resp = requests.get(f"http://127.0.0.1:8000/api/accounts/user-links/?email={email_usuario}")
            if resp.status_code == 200:
                data = resp.json()
                url_active = data.get("form_link1", "")
                url_leaver = data.get("form_link2", "")
                url_hr = data.get("form_link3", "")
                st.success("‚úÖ Links cargados desde tu cuenta.")
            else:
                st.error("No se pudieron cargar los links del usuario.")
        except Exception as e:
            st.error(f"Error conectando con backend: {e}")
    else:
        st.warning("No se recibi√≥ el email del usuario en la URL (ej: ?email=correo@ejemplo.com)")

    st.divider()
    st.subheader("Par√°metros")
    min_responses = st.number_input("M√≠n. respuestas por √°rea para mostrar (umbral)", value=10, min_value=1, step=1)
    top_n = st.slider("Top N drivers a destacar", 3, 15, 7, step=1)

if not (url_active and url_leaver and url_hr):
    st.info("Pega las **tres** URLs p√∫blicas para continuar.")
    st.markdown("</div>", unsafe_allow_html=True)
    st.stop()

try:
    df_active = load_table(url_active)
    df_leaver = load_table(url_leaver)
    df_hr = load_table(url_hr)
    st.success(f"Cargados: activos {len(df_active):,} filas ¬∑ egresos {len(df_leaver):,} ¬∑ HR {len(df_hr):,}")
except Exception as e:
    st.error(f"No se pudieron leer las URLs: {e}")
    st.markdown("</div>", unsafe_allow_html=True)
    st.stop()

# Mapear columnas
m_active = map_cols(df_active, ACTIVE_REQUIRED, ACTIVE_OPTIONAL)
m_leaver = map_cols(df_leaver, LEAVER_REQUIRED, LEAVER_OPTIONAL)
m_hr = map_cols(df_hr, HR_REQUIRED, HR_OPTIONAL)

TAB1, TAB2, TAB3 = st.tabs(["Conclusiones y correlaciones", "Chat experto", "Explorar archivos"])

# TAB 1 ‚Äì CONCLUSIONES Y CORRELACIONES

with TAB1:
    st.subheader("üß≠ Diagn√≥stico integral de rotaci√≥n")

    active_text_cols = [
        m_active.get("razon_calificacion"),
        m_active.get("razones_posible_salida"),
        m_active.get("cambio_para_quedarte"),
        m_active.get("comentario_adicional"),
    ]
    active_text_cols = [c for c in active_text_cols if c and c in df_active.columns]
    if active_text_cols:
        df_active["__reasons_text_activos"] = df_active[active_text_cols].astype(str).agg(" | ".join, axis=1)
        m_active["razones_texto"] = "__reasons_text_activos"

    leaver_text_cols = [
        m_leaver.get("otros_factores"),
        m_leaver.get("mejoras_retencion"),
        m_leaver.get("sugerencia_final"),
    ]
    leaver_text_cols = [c for c in leaver_text_cols if c and c in df_leaver.columns]
    if leaver_text_cols:
        df_leaver["__reasons_text_egresos"] = df_leaver[leaver_text_cols].astype(str).agg(" | ".join, axis=1)
        m_leaver["comentarios"] = "__reasons_text_egresos"

    try:
        corr_df = correlate_with_intent(df_active, m_active)
    except Exception as e:
        st.error(f"Error calculando correlaciones: {e}")
        corr_df = pd.DataFrame()

    try:
        reasons_df = summarize_reasons(df_active, df_leaver, m_active, m_leaver)
    except Exception as e:
        st.error(f"Error procesando razones de salida: {e}")
        reasons_df = pd.DataFrame()

    try:
        risk_df = area_risk(df_active, m_active)
        if len(risk_df):
            risk_df = risk_df[risk_df["n"] >= min_responses]
    except Exception as e:
        st.error(f"Error calculando riesgo por √°rea: {e}")
        risk_df = pd.DataFrame()

    cols = st.columns(2)
    with cols[0]:
        st.markdown("**Drivers asociados a intenci√≥n de salida** (corr. Pearson; negativo = protector, positivo = riesgo)")
        if len(corr_df):
            st.dataframe(corr_df.head(top_n), use_container_width=True)
        else:
            st.info("No se pudieron calcular correlaciones. Revisa columnas de drivers en la encuesta de activos.")
    with cols[1]:
        st.markdown("**Razones m√°s mencionadas (activos + egresos)**")
        if len(reasons_df):
            st.dataframe(reasons_df.head(top_n), use_container_width=True)
        else:
            st.info("No se detectaron razones. Revisa campos de texto y motivo de salida.")

    st.markdown("---")
    st.markdown("**Riesgo por √°rea (intenci√≥n y eNPS/engagement)**")
    if len(risk_df):
        st.dataframe(risk_df, use_container_width=True)
    else:
        st.info("No hay suficientes datos por √°rea o faltan columnas clave (√°rea, intenci√≥n, eNPS/engagement).")


    st.markdown("---")
    st.subheader("üè¢ Gesti√≥n Humana: KPIs, causas y capacidades")
    try:
        kpis_df, causas_df, pract_df, hr_text = hr_dashboard(df_hr, m_hr)
        if len(kpis_df):
            st.markdown("**KPIs**")
            st.dataframe(kpis_df, use_container_width=True)
        if len(causas_df):
            st.markdown("**Causas de rotaci√≥n (percepci√≥n HR)**")
            st.dataframe(causas_df, use_container_width=True)
        if len(pract_df):
            st.markdown("**Capacidades y pr√°cticas (s√≠/efectivo)**")
            st.dataframe(pract_df.head(15), use_container_width=True)
        if hr_text:
            st.caption(hr_text[:1000])
    except Exception as e:
        st.error(f"Error en panel HR: {e}")

    # Conclusiones accionables
    st.markdown("---")
    st.subheader("üìå Conclusiones y recomendaciones (autom√°tico)")

    def render_takeaways():
        items = []
        if len(corr_df):
            worst = corr_df.tail(3).index.tolist()
            best = corr_df.head(3).index.tolist()
            items.append(f"**Drivers de mayor riesgo**: {', '.join(worst)}")
            items.append(f"**Drivers protectores**: {', '.join(best)}")
        if len(reasons_df):
            top_reasons = reasons_df.head(3)["categoria"].tolist()
            items.append(f"**Motivos m√°s reportados**: {', '.join(top_reasons)}")
        if len(risk_df):
            high_risk = risk_df.head(3)[m_active.get("area")].tolist()
            items.append(f"**√Åreas con mayor riesgo**: {', '.join(high_risk)}")
        if 'causas_df' in locals() and len(causas_df):
            focus = causas_df.head(3)["causa"].tolist()
            items.append(f"**Causas seg√∫n HR**: {', '.join(focus)}")
        if 'pract_df' in locals() and len(pract_df):
            gaps = pract_df.sort_values("% s√≠/efectivo").head(3)["pr√°ctica"].tolist()
            items.append(f"**Brechas de capacidad en HR**: {', '.join(gaps)}")
        if not items:
            items.append("No hay suficientes datos para inferir conclusiones. Verifica mapeo de columnas y calidad de respuestas.")
        return items

    for bullet in render_takeaways():
        st.markdown(f"- {bullet}")

    st.caption("*Contenido referencial; no reemplaza asesor√≠a legal/SSO.*")

# TAB 2 ‚Äì CHAT EXPERTO
with TAB2:
    st.subheader("üí¨ Chat experto en fidelizaci√≥n y experiencia del colaborador")

    if "rot_chat_history" not in st.session_state:
        st.session_state.rot_chat_history = []

    base_context = {
        "active_cols": list(df_active.columns),
        "leaver_cols": list(df_leaver.columns),
        "hr_cols": list(df_hr.columns),
        "m_active": m_active,
        "m_leaver": m_leaver,
        "m_hr": m_hr,
        "corr_top": corr_df.tail(min(5, len(corr_df))).reset_index().to_dict(orient="records") if 'corr_df' in locals() and len(corr_df) else [],
        "reasons_top": reasons_df.head(min(5, len(reasons_df))).to_dict(orient="records") if 'reasons_df' in locals() and len(reasons_df) else [],
        "risk_top": risk_df.head(min(5, len(risk_df))).to_dict(orient="records") if 'risk_df' in locals() and len(risk_df) else [],
    }
    # Historial
    for role, msg in st.session_state.rot_chat_history:
        with st.chat_message(role):
            st.markdown(msg)

    user_q = st.chat_input("Pregunta algo como: '¬øqu√© quick wins implementar en 30 d√≠as?' o '¬øc√≥mo reducir salidas por liderazgo?'")
    if user_q:
        st.session_state.rot_chat_history.append(("user", user_q))
        with st.chat_message("user"):
            st.markdown(user_q)

        answer = build_llm_answer(base_context, user_q)

        with st.chat_message("assistant"):
            st.markdown(answer)
        st.session_state.rot_chat_history.append(("assistant", answer))

# TAB 3 ‚Äì EXPLORAR ARCHIVOS
with TAB3:
    st.subheader("üëÄ Ver/filtrar encuestas")

    ds = {
        "Activos": df_active,
        "Egresos": df_leaver,
        "Gesti√≥n Humana": df_hr,
    }
    which = st.selectbox("Selecciona dataset", options=list(ds.keys()))
    df = ds[which]

    if len(df) == 0:
        st.warning("La fuente no tiene filas.")
    else:
        max_preview = min(1000, len(df))
        default_preview = min(20, max_preview)

        if max_preview == 1:
            n_preview = 1
            st.caption("Mostrando 1 fila (no hay m√°s para previsualizar).")
        else:
            n_preview = st.slider(
                "Filas a mostrar (preview)",
                min_value=1,
                max_value=max_preview,
                value=default_preview,
                step=1,
                key=f"slider_{which}",
            )

        cols_sel = st.multiselect(
            "Columnas a mostrar (opcional)",
            options=list(df.columns),
            default=list(df.columns)[:min(10, len(df.columns))],
            key=f"cols_{which}",
        )
        view_df = df[cols_sel] if cols_sel else df
        st.dataframe(view_df.head(n_preview), use_container_width=True)
        st.download_button(
            f"‚¨áÔ∏è Descargar {which} (CSV)",
            data=df.to_csv(index=False).encode("utf-8"),
            file_name=f"{slug(which)}.csv",
            mime="text/csv",
            key=f"dl_{which}",
        )

st.markdown("</div>", unsafe_allow_html=True)

st.markdown(
    """
    <div class='footer'>
        ¬© 2025 Solution Hr ¬∑ Diagn√≥stico de rotaci√≥n y fidelizaci√≥n.
    </div>
    """,
    unsafe_allow_html=True,
)
